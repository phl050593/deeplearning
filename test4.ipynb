{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676405b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lu050\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\gradio\\utils.py:1028: UserWarning: Expected 5 arguments for function <function predict_fuzzy_team_grid at 0x00000115188336A0>, received 62.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lu050\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\gradio\\utils.py:1036: UserWarning: Expected maximum 5 arguments for function <function predict_fuzzy_team_grid at 0x00000115188336A0>, received 62.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\lu050\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\gradio\\queueing.py\", line 625, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<5 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\lu050\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\gradio\\route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<11 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\lu050\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\gradio\\blocks.py\", line 2191, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<8 lines>...\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\lu050\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\gradio\\blocks.py\", line 1702, in call_function\n",
      "    prediction = await anyio.to_thread.run_sync(  # type: ignore\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        fn, *processed_input, limiter=self.limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\lu050\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "        func, args, abandon_on_cancel=abandon_on_cancel, limiter=limiter\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\lu050\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2470, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\lu050\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 967, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"c:\\Users\\lu050\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\gradio\\utils.py\", line 894, in wrapper\n",
      "    response = f(*args, **kwargs)\n",
      "TypeError: predict_fuzzy_team_grid() takes 5 positional arguments but 62 were given\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ============ 1. 資料預處理 ============\n",
    "\n",
    "# 讀資料\n",
    "winners = pd.read_csv('./data/winners.csv')\n",
    "drivers = pd.read_csv('./data/drivers_updated.csv')\n",
    "laps = pd.read_csv('./data/fastest_laps_updated.csv')\n",
    "teams = pd.read_csv('./data/teams_updated.csv')\n",
    "winners['year'] = pd.to_datetime(winners['Date']).dt.year\n",
    "\n",
    "# 時間字串轉秒\n",
    "def time_to_seconds(x):\n",
    "    if pd.isna(x): return 0\n",
    "    if isinstance(x, (float, int)): return float(x)\n",
    "    if ':' in x:\n",
    "        parts = x.split(':')\n",
    "        if len(parts) == 3:\n",
    "            h, m, s = parts\n",
    "            return int(h)*3600 + int(m)*60 + float(s)\n",
    "        elif len(parts) == 2:\n",
    "            m, s = parts\n",
    "            return int(m)*60 + float(s)\n",
    "        else:\n",
    "            return float(parts[0])\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "winners['Time_sec'] = winners['Time'].apply(time_to_seconds)\n",
    "laps['LapTime_sec'] = laps['Time'].apply(time_to_seconds)\n",
    "\n",
    "# Label Encoding\n",
    "le_driver = LabelEncoder().fit(pd.concat([winners['Winner'], drivers['Driver']]).astype(str))\n",
    "le_team = LabelEncoder().fit(pd.concat([winners['Car'], teams['Team'], drivers['Car']]).astype(str))\n",
    "le_gp = LabelEncoder().fit(winners['Grand Prix'])\n",
    "le_nat = LabelEncoder().fit(drivers['Nationality'].astype(str))\n",
    "\n",
    "# 年度PTS、國籍、車隊PTS\n",
    "driver_pts = drivers[['Driver', 'Car', 'PTS', 'year']].drop_duplicates()\n",
    "driver_pts.columns = ['Driver', 'Car', 'driver_pts', 'year']\n",
    "team_pts = teams[['Team', 'PTS', 'year']].drop_duplicates()\n",
    "team_pts.columns = ['Car', 'team_pts', 'year']\n",
    "driver_nat = drivers[['Driver', 'Nationality', 'Car', 'year']].drop_duplicates()\n",
    "driver_nat.columns = ['Driver', 'Nationality', 'Car', 'year']\n",
    "laps_best = laps.groupby(['Grand Prix', 'Driver', 'Car', 'year'])['LapTime_sec'].min().reset_index()\n",
    "laps_best.columns = ['Grand Prix', 'Driver', 'Car', 'year', 'best_lap_time']\n",
    "\n",
    "df = winners.merge(driver_pts, left_on=['Winner', 'Car', 'year'], right_on=['Driver', 'Car', 'year'], how='left')\n",
    "df = df.merge(team_pts, on=['Car', 'year'], how='left')\n",
    "df = df.merge(driver_nat, left_on=['Winner', 'Car', 'year'], right_on=['Driver', 'Car', 'year'], how='left', suffixes=('', '_nat'))\n",
    "df = df.merge(laps_best, left_on=['Grand Prix', 'Winner', 'Car', 'year'],\n",
    "              right_on=['Grand Prix', 'Driver', 'Car', 'year'], how='left', suffixes=('', '_lap'))\n",
    "\n",
    "# 填補缺失\n",
    "df['driver_pts'] = df['driver_pts'].fillna(0)\n",
    "df['team_pts'] = df['team_pts'].fillna(0)\n",
    "df['Nationality'] = df['Nationality'].fillna('Unknown')\n",
    "df['best_lap_time'] = df['best_lap_time'].fillna(0)\n",
    "df['Laps'] = df['Laps'].fillna(0)\n",
    "df['Time_sec'] = df['Time_sec'].fillna(0)\n",
    "\n",
    "# 編碼\n",
    "df['driver_id'] = le_driver.transform(df['Winner'].astype(str))\n",
    "df['team_id'] = le_team.transform(df['Car'].astype(str))\n",
    "df['gp_id'] = le_gp.transform(df['Grand Prix'])\n",
    "df['nat_id'] = le_nat.transform(df['Nationality'].astype(str))\n",
    "\n",
    "# 特徵欄位\n",
    "df['Pos'] = pd.to_numeric(df['Pos'], errors='coerce').fillna(0)\n",
    "\n",
    "# 歷史三場平均名次、最佳名次\n",
    "df = df.sort_values(['Winner', 'year'])\n",
    "df['hist_mean_pos'] = df.groupby('Winner')['Pos'].transform(lambda x: x.rolling(3, min_periods=1).mean())\n",
    "df['hist_best_pos'] = df.groupby('Winner')['Pos'].transform(lambda x: x.rolling(3, min_periods=1).min())\n",
    "\n",
    "feature_cols = [\n",
    "    'driver_id',      # 車手ID\n",
    "    'team_id',        # 車隊ID\n",
    "    'gp_id',          # Grand Prix\n",
    "    'year',           # 年份\n",
    "    'Pos',            # 起跑位\n",
    "    'Laps',           # 圈數\n",
    "    'Time_sec',       # 比賽時間（秒）\n",
    "    'driver_pts',     # 車手年度分數\n",
    "    'team_pts',       # 車隊年度分數\n",
    "    'nat_id',         # 國籍ID\n",
    "    'best_lap_time',  # 本場最快圈速（秒）\n",
    "    'hist_mean_pos',  # 近三場平均名次\n",
    "    'hist_best_pos',  # 近三場最佳名次\n",
    "]\n",
    "\n",
    "# ========== 2. 場次集體樣本製作 ==========\n",
    "def create_race_samples(df, n_drivers=20):\n",
    "    races = []\n",
    "    labels = []\n",
    "    grouped = df.groupby(['year', 'Grand Prix'])\n",
    "    for (year, gp), race in grouped:\n",
    "        race = race.sort_values('Pos')\n",
    "        if len(race) < n_drivers: continue\n",
    "        race = race.iloc[:n_drivers]\n",
    "        features = race[feature_cols].values\n",
    "        if features.shape[0] != n_drivers: continue\n",
    "        races.append(features)\n",
    "        label_idx = np.where(race['Position'].values == 1)[0]\n",
    "        if len(label_idx) == 0: continue\n",
    "        labels.append(label_idx[0])\n",
    "    return np.array(races), np.array(labels)\n",
    "\n",
    "X, y = create_race_samples(df)\n",
    "print('Race set shape:', X.shape, 'Label shape:', y.shape)\n",
    "print('features:', feature_cols)\n",
    "\n",
    "# ========== 3. PyTorch Dataset ==========\n",
    "class F1RaceSet(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.long)\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "# ========== 4. Set Transformer Model ==========\n",
    "class DriverMLP(nn.Module):\n",
    "    def __init__(self, in_dim, hidden=64, out_dim=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden, out_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class SetAttentionBlock(nn.Module):\n",
    "    def __init__(self, dim, heads=4):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(dim, heads, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(dim)\n",
    "    def forward(self, x):\n",
    "        h, _ = self.attn(x, x, x)\n",
    "        return self.norm(x + h)\n",
    "\n",
    "class F1CollectiveSetTransformer(nn.Module):\n",
    "    def __init__(self, driver_feat_dim, set_dim=64, n_drivers=20):\n",
    "        super().__init__()\n",
    "        self.driver_mlp = DriverMLP(driver_feat_dim, out_dim=set_dim)\n",
    "        self.set_block = SetAttentionBlock(set_dim, heads=4)\n",
    "        self.final = nn.Linear(set_dim, 1)  # 每人一個logit\n",
    "        self.n_drivers = n_drivers\n",
    "    def forward(self, x):\n",
    "        dfeat = self.driver_mlp(x)           # (batch, n_drivers, set_dim)\n",
    "        set_out = self.set_block(dfeat)      # (batch, n_drivers, set_dim)\n",
    "        logits = self.final(set_out).squeeze(-1)  # (batch, n_drivers)\n",
    "        return logits\n",
    "\n",
    "# ========== 5. 訓練流程 ==========\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "trainset = F1RaceSet(X_train, y_train)\n",
    "valset = F1RaceSet(X_val, y_val)\n",
    "train_loader = DataLoader(trainset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(valset, batch_size=32, shuffle=False)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = F1CollectiveSetTransformer(driver_feat_dim=X.shape[2], n_drivers=20).to(device)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-3)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "best_acc = 0\n",
    "for epoch in range(1, 31):\n",
    "    model.train()\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        logits = model(xb)\n",
    "        loss = loss_fn(logits, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    # 驗證\n",
    "    model.eval()\n",
    "    correct = 0; total = 0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            logits = model(xb)\n",
    "            pred = torch.argmax(logits, dim=1)\n",
    "            correct += (pred == yb).sum().item()\n",
    "            total += yb.size(0)\n",
    "    acc = correct / total\n",
    "    print(f\"Epoch {epoch}: val acc = {acc:.4f}\")\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        torch.save(model.state_dict(), \"best_f1_collective.pth\")\n",
    "print(\"Best val acc:\", best_acc)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
