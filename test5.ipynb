{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4090a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import gradio as gr\n",
    "\n",
    "\n",
    "# è³‡æ–™è¼‰å…¥\n",
    "drivers_df = pd.read_csv(\"./data/drivers_updated.csv\")\n",
    "winners_df = pd.read_csv(\"./data/winners.csv\")\n",
    "teams_df = pd.read_csv(\"./data/teams_updated.csv\")\n",
    "laps_df = pd.read_csv(\"./data/fastest_laps_updated.csv\")\n",
    "\n",
    "\n",
    "# æ¨¡åž‹å®šç¾©\n",
    "class MultiTaskLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes_driver, num_classes_team, num_classes_pos, stat_feature_size=1, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size, \n",
    "            hidden_size, \n",
    "            num_layers=num_layers, \n",
    "            batch_first=True, \n",
    "            bidirectional=True\n",
    "        )\n",
    "        combined_size = hidden_size * 2 + stat_feature_size\n",
    "        self.driver_head = nn.Linear(combined_size, num_classes_driver)\n",
    "        self.team_head = nn.Linear(combined_size, num_classes_team)\n",
    "        self.pos_head = nn.Linear(combined_size, num_classes_pos)\n",
    "\n",
    "    def forward(self, x, stats):\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        h = lstm_out[:, -1, :]  # Use last time step\n",
    "        combined = torch.cat([h, stats], dim=1)\n",
    "        return self.driver_head(combined), self.team_head(combined), self.pos_head(combined)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def predict(year, gp_name, show_team_rank=True, show_internal_rank=False):\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    # ä¿®æ­£ï¼šdrivers å¤šä¿ç•™ Pos æ¬„ä½\n",
    "    drivers = drivers_df[[\"Driver\", \"Car\", \"year\", \"Pos\"]].copy()\n",
    "    winners = winners_df.copy()\n",
    "    teams = teams_df.copy()\n",
    "    laps_data = laps_df.copy()\n",
    "\n",
    "    winners[\"year\"] = pd.to_datetime(winners[\"Date\"]).dt.year\n",
    "    winners = winners.rename(columns={\"Winner\": \"Driver\"})\n",
    "\n",
    "    # merge åªè¦ä¸€æ¬¡\n",
    "    df = winners.merge(drivers, on=[\"Driver\", \"Car\", \"year\"], how=\"left\")\n",
    "    df = df.merge(laps_df, on=[\"Grand Prix\", \"Driver\", \"Car\", \"year\"], how=\"left\")\n",
    "    df = df.merge(teams_df, left_on=[\"Car\", \"year\"], right_on=[\"Team\", \"year\"], how=\"left\")\n",
    "\n",
    "    # åªä¿ç•™ Pos æ¬„ä½å¯ä»¥è½‰æˆæ•¸å­—çš„è³‡æ–™\n",
    "    df = df[pd.to_numeric(df[\"Pos_x\"], errors=\"coerce\").notna()].copy()\n",
    "    df[\"Pos\"] = pd.to_numeric(df[\"Pos_x\"], errors=\"coerce\")\n",
    "\n",
    "    # åªç•™ä¸‹ä½ è¦çš„æ¬„ä½\n",
    "    df = df[[\"Grand Prix\", \"Date\", \"Driver\", \"Car\", \"year\", \"Pos\", \"Team\"]]\n",
    "    df = df.dropna(subset=[\"Pos\", \"Driver\", \"Team\", \"Grand Prix\"])\n",
    "\n",
    "    start_year = max(1950, year - 20)\n",
    "    df = df[(df[\"year\"] >= start_year) & (df[\"year\"] <= year)].copy()\n",
    "    if df.empty:\n",
    "        return \"æ­·å²è³‡æ–™ä¸è¶³\"\n",
    "\n",
    "    le_driver = LabelEncoder()\n",
    "    le_team = LabelEncoder()\n",
    "    le_gp = LabelEncoder()\n",
    "    df[\"Driver_enc\"] = le_driver.fit_transform(df[\"Driver\"].astype(str))\n",
    "    df[\"Team_enc\"] = le_team.fit_transform(df[\"Team\"].astype(str))\n",
    "    df[\"GP_enc\"] = le_gp.fit_transform(df[\"Grand Prix\"].astype(str))  # ç•™ä½œæª¢æŸ¥ï¼Œä¸åƒèˆ‡è¨“ç·´\n",
    "\n",
    "    main_features = [\"year\"]  # ä¸ä½¿ç”¨ GP_enc\n",
    "    df[main_features] = df[main_features].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "\n",
    "    def get_seq_features(df, driver, year, n_seq=10):\n",
    "        hist = df[(df[\"Driver\"] == driver) & (df[\"year\"] < year)].sort_values(\"year\", ascending=False)\n",
    "        feats = hist.head(n_seq)[main_features].values\n",
    "        if len(feats) < n_seq:\n",
    "            pad = np.zeros((n_seq - len(feats), len(main_features)))\n",
    "            feats = np.vstack([feats, pad])\n",
    "        return feats\n",
    "\n",
    "    def get_stat_features(df, driver, year):\n",
    "        recent = df[(df[\"Driver\"] == driver) & (df[\"year\"] >= year - 5) & (df[\"year\"] < year)]\n",
    "        total_wins = len(recent)\n",
    "        return np.array([total_wins], dtype=np.float32)\n",
    "\n",
    "    X_seq, X_stat, y_driver, y_team, y_pos = [], [], [], [], []\n",
    "    for _, row in df.iterrows():\n",
    "        X_seq.append(get_seq_features(df, row[\"Driver\"], row[\"year\"]))\n",
    "        X_stat.append(get_stat_features(df, row[\"Driver\"], row[\"year\"]))\n",
    "        y_driver.append(row[\"Driver\"])\n",
    "        y_team.append(row[\"Team\"])\n",
    "        y_pos.append(row[\"Pos\"])\n",
    "\n",
    "    if not X_seq:\n",
    "        return \"åºåˆ—è³‡æ–™ä¸è¶³\"\n",
    "\n",
    "    X_seq = np.stack(X_seq)\n",
    "    X_stat = np.stack(X_stat)\n",
    "    y_driver_enc = le_driver.transform(y_driver)\n",
    "    y_team_enc = le_team.transform(y_team)\n",
    "    y_pos_tensor = torch.tensor(y_pos, dtype=torch.float32).to(device)\n",
    "\n",
    "    model = MultiTaskLSTMClassifier(\n",
    "        input_size=len(main_features),\n",
    "        hidden_size=128,\n",
    "        num_classes_driver=len(le_driver.classes_),\n",
    "        num_classes_team=len(le_team.classes_),\n",
    "        num_classes_pos=1,\n",
    "        stat_feature_size=X_stat.shape[1],\n",
    "    ).to(device)\n",
    "\n",
    "    model_path = f\"./model/model_f1_{year}_{gp_name}.pt\"\n",
    "    if os.path.exists(model_path):\n",
    "        state_dict = torch.load(model_path, map_location=device, weights_only=True)\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "    else:\n",
    "        X_tensor = torch.tensor(X_seq, dtype=torch.float32).to(device)\n",
    "        X_stat_tensor = torch.tensor(X_stat, dtype=torch.float32).to(device)\n",
    "        y_driver_tensor = torch.tensor(y_driver_enc, dtype=torch.long).to(device)\n",
    "        y_team_tensor = torch.tensor(y_team_enc, dtype=torch.long).to(device)\n",
    "        optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "        criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
    "        criterion_ce = nn.CrossEntropyLoss()\n",
    "        criterion_pos = nn.SmoothL1Loss()\n",
    "\n",
    "        DECAY = -0.08  # èª¿èˆŠè³‡æ–™å½±éŸ¿åº¦\n",
    "        weights = np.exp(DECAY * (year - df[\"year\"].values))\n",
    "        weights_tensor = torch.tensor(weights, dtype=torch.float32).to(device)\n",
    "\n",
    "        # ==== ç¬¬ä¸€è¼ªï¼šå¸¸è¦è¨“ç·´ ====\n",
    "        for _ in range(500):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out_driver, out_team, out_pos = model(X_tensor, X_stat_tensor)\n",
    "            loss_driver = criterion(out_driver, y_driver_tensor)\n",
    "            loss_team = criterion(out_team, y_team_tensor)\n",
    "            loss_pos = criterion_pos(out_pos.squeeze(), y_pos_tensor)\n",
    "            loss = 0.2 * (loss_driver * weights_tensor).mean() + \\\n",
    "                   0.3 * (loss_team * weights_tensor).mean() + \\\n",
    "                   0.5 * loss_pos\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        # ==== ç”¢ç”Ÿ pseudo label (è»Ÿæ¨™ç±¤) ====\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            out_driver, _, _ = model(X_tensor, X_stat_tensor)\n",
    "            pseudo_soft_label = torch.softmax(out_driver / 10, dim=1)  \n",
    "\n",
    "        # ==== ç¬¬äºŒè¼ªï¼špseudo label è’¸é¤¾è¨“ç·´ ====\n",
    "        alpha = 0.7  # çœŸå¯¦æ¨™ç±¤ loss ä½”æ¯”\n",
    "        for _ in range(150):  # pseudo label å†è¨“ç·´ 150 è¼ªå³å¯\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            out_driver, out_team, out_pos = model(X_tensor, X_stat_tensor)\n",
    "            # ç¡¬æ¨™ç±¤loss\n",
    "            loss_driver_hard = criterion_ce(out_driver, y_driver_tensor)\n",
    "            # è»Ÿæ¨™ç±¤lossï¼ˆKLDivï¼‰\n",
    "            loss_driver_soft = nn.KLDivLoss(reduction=\"batchmean\")(\n",
    "                torch.log_softmax(out_driver, dim=1),\n",
    "                pseudo_soft_label\n",
    "            )\n",
    "            loss_team = criterion(out_team, y_team_tensor)\n",
    "            loss_pos = criterion_pos(out_pos.squeeze(), y_pos_tensor)\n",
    "            # æ··åˆloss\n",
    "            loss = alpha * loss_driver_hard + (1-alpha) * loss_driver_soft \\\n",
    "                   + 0.3 * (loss_team * weights_tensor).mean() + \\\n",
    "                   0.5 * loss_pos\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "\n",
    "    if gp_name not in le_gp.classes_:\n",
    "        return \"GP åç¨±ç„¡æ•ˆ\"\n",
    "\n",
    "    recent_years = set(range(year - 3, year))\n",
    "    driver_years = drivers.groupby(\"Driver\")[\"year\"].apply(set).to_dict()\n",
    "    active_indices = [i for i, name in enumerate(le_driver.classes_) if recent_years & driver_years.get(name, set())]\n",
    "    if len(active_indices) == 0:\n",
    "        return \"æŸ¥ç„¡è¶³å¤ æ´»èºè»Šæ‰‹\"\n",
    "\n",
    "    full_df = winners.merge(teams, left_on=[\"Car\", \"year\"], right_on=[\"Team\", \"year\"], how=\"left\")\n",
    "    full_df = full_df.dropna(subset=[\"Driver\", \"Team\"])\n",
    "    last_team_map = (\n",
    "        full_df.sort_values(\"year\")\n",
    "        .drop_duplicates(subset=[\"Driver\"], keep=\"last\")\n",
    "        .set_index(\"Driver\")[\"Team\"]\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    driver_records = []\n",
    "    for idx in active_indices:\n",
    "        driver = le_driver.classes_[idx]\n",
    "        team = last_team_map.get(driver, \"æœªçŸ¥è»ŠéšŠ\")\n",
    "        input_tensor = torch.tensor(np.expand_dims(get_seq_features(df, driver, year), axis=0), dtype=torch.float32).to(device)\n",
    "        stat_tensor = torch.tensor(np.expand_dims(get_stat_features(df, driver, year), axis=0), dtype=torch.float32).to(device)\n",
    "        with torch.no_grad():\n",
    "            out_driver, _, out_pos = model(input_tensor, stat_tensor)\n",
    "            TEMPERATURE = 5  \n",
    "            confidence = torch.softmax(out_driver / TEMPERATURE, dim=1)[0, idx].item() * 100\n",
    "            position_score = out_pos.item()\n",
    "        driver_records.append({\"driver\": driver, \"team\": team, \"confidence\": confidence, \"position_score\": position_score})\n",
    "\n",
    "    df_pred = pd.DataFrame(driver_records).sort_values(by=\"confidence\", ascending=False)\n",
    "\n",
    "    result_lines = []\n",
    "    team_scores = df_pred.groupby(\"team\")[\"confidence\"].sum().sort_values(ascending=False)\n",
    "\n",
    "    if show_team_rank:\n",
    "        result_lines.append(\"ðŸ è»ŠéšŠç¸½æŽ’åï¼š\")\n",
    "        for idx, (team, score) in enumerate(team_scores.items(), 1):\n",
    "            result_lines.append(f\"{idx}. {team}ï¼ˆä¿¡å¿ƒåº¦ {score:.2f}%ï¼‰\")\n",
    "        result_lines.append(\"\")\n",
    "\n",
    "    if show_internal_rank:\n",
    "        result_lines.append(\"ðŸ‘¥ è»ŠéšŠå…§éƒ¨æŽ’åºï¼š\")\n",
    "        internal_sorted = df_pred.sort_values([\"team\", \"confidence\"], ascending=[True, False])\n",
    "        for team in team_scores.index:\n",
    "            result_lines.append(f\"{team}ï¼š\")\n",
    "            for _, row in internal_sorted[internal_sorted[\"team\"] == team].iterrows():\n",
    "                result_lines.append(f\"  {row['driver']}ï¼ˆ{row['confidence']:.2f}%ï¼‰\")\n",
    "        result_lines.append(\"\")\n",
    "\n",
    "    for rank, row in enumerate(df_pred.itertuples(), 1):\n",
    "        result_lines.append(f\"ç¬¬ {rank} åï¼š{row.driver}ï¼ˆ{row.team}ï¼‰ \\tä¿¡å¿ƒåº¦ï¼š{row.confidence:.2f}% \\tä½ç½®åˆ†æ•¸ï¼š{row.position_score:.2f}\")\n",
    "\n",
    "    return \"\\n\".join(result_lines)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Gradio UI ===\n",
    "try:\n",
    "    winners_ui = pd.read_csv(\"./data/winners.csv\")\n",
    "    gp_names_for_ui = sorted(winners_ui[\"Grand Prix\"].dropna().unique().tolist())\n",
    "except:\n",
    "    gp_names_for_ui = [\"ERROR\"]\n",
    "\n",
    "def wrapped_predict(year, gp_name, driver_count_option, show_team_rank, show_internal_rank):\n",
    "    full_text = predict(year, gp_name, show_team_rank, show_internal_rank)\n",
    "    lines = full_text.splitlines()\n",
    "\n",
    "    # æ“·å–å€‹äººåæ¬¡å€å¡Š\n",
    "    if driver_count_option == \"Top 5\":\n",
    "        core = [line for line in lines if line.startswith(\"ç¬¬ \")][:5]\n",
    "    elif driver_count_option == \"Top 10\":\n",
    "        core = [line for line in lines if line.startswith(\"ç¬¬ \")][:10]\n",
    "    else:\n",
    "        core = [line for line in lines if line.startswith(\"ç¬¬ \")]\n",
    "\n",
    "    # æ“·å–è»ŠéšŠæŽ’åèˆ‡æŽ’åºå€å¡Š\n",
    "    others = []\n",
    "    capture = False\n",
    "    for line in lines:\n",
    "        if line.startswith(\"ðŸ\") or line.startswith(\"ðŸ‘¥\"):\n",
    "            capture = True\n",
    "        elif line.startswith(\"ç¬¬ \"):\n",
    "            capture = False\n",
    "        if capture:\n",
    "            others.append(line)\n",
    "\n",
    "    result = \"\\n\".join(core + [\"\"] + others)\n",
    "    result += f\"\\n\\nðŸš¥ é æ¸¬è»Šæ‰‹ç¸½æ•¸ï¼š{len(core)} ä½\"\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# ðŸŽï¸ F1 æŽ’åé æ¸¬\")\n",
    "    year = gr.Number(label=\"å¹´ä»½\", value=2025)\n",
    "    gp_name = gr.Dropdown(choices=gp_names_for_ui, label=\"Grand Prix åç¨±\", value=gp_names_for_ui[0])\n",
    "    driver_count_option = gr.Dropdown(choices=[\"Top 5\", \"Top 10\", \"å…¨éƒ¨\"], label=\"é æ¸¬è»Šæ‰‹æ•¸é‡\", value=\"å…¨éƒ¨\")\n",
    "    show_team_rank = gr.Checkbox(label=\"é¡¯ç¤ºè»ŠéšŠç¸½æŽ’å\", value=True)\n",
    "    show_internal_rank = gr.Checkbox(label=\"é¡¯ç¤ºè»ŠéšŠå…§æŽ’åº\", value=False)\n",
    "    output = gr.Textbox(label=\"é æ¸¬çµæžœ\", lines=30)\n",
    "    btn = gr.Button(\"é æ¸¬\")\n",
    "    btn.click(\n",
    "        wrapped_predict,\n",
    "        inputs=[year, gp_name, driver_count_option, show_team_rank, show_internal_rank],\n",
    "        outputs=output\n",
    "    )\n",
    "\n",
    "demo.launch()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
