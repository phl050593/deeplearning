{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "36f4ba46",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lu050\\anaconda3\\envs\\pytorch\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lu050\\AppData\\Local\\Temp\\ipykernel_12392\\2684882543.py:101: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:257.)\n",
      "  X_seq_input = torch.tensor([feats_seq], dtype=torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import xgboost as xgb\n",
    "import gradio as gr\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ==== 1. 讀取資料 ====\n",
    "winners = pd.read_csv('./data/winners.csv')\n",
    "drivers = pd.read_csv('./data/drivers_updated.csv')\n",
    "laps = pd.read_csv('./data/fastest_laps_updated.csv')\n",
    "teams = pd.read_csv('./data/teams_updated.csv')\n",
    "\n",
    "winners['year'] = pd.to_datetime(winners['Date']).dt.year\n",
    "\n",
    "# ==== 2. 合併資料（以 Winner+Car+year 為主鍵）====\n",
    "df = winners.merge(drivers, left_on=['Winner', 'Car', 'year'], right_on=['Driver', 'Car', 'year'], how='left')\n",
    "df = df.merge(laps, left_on=['Grand Prix', 'Winner', 'Car', 'year'], right_on=['Grand Prix', 'Driver', 'Car', 'year'], how='left')\n",
    "df = df.merge(teams, left_on=['Car', 'year'], right_on=['Team', 'year'], how='left')\n",
    "\n",
    "main_features = ['Grid', 'Laps', 'Time', 'Position']\n",
    "label_col = 'Winner'\n",
    "\n",
    "for col in main_features:\n",
    "    if col not in df.columns:\n",
    "        df[col] = 0\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)\n",
    "\n",
    "# Label Encoding\n",
    "le_label = LabelEncoder()\n",
    "df['Winner_enc'] = le_label.fit_transform(df[label_col].astype(str))\n",
    "le_gp = LabelEncoder()\n",
    "df['GrandPrix_enc'] = le_gp.fit_transform(df['Grand Prix'].astype(str))\n",
    "le_team = LabelEncoder()\n",
    "df['Team_enc'] = le_team.fit_transform(df['Car'].astype(str)) # 用Car代表Team\n",
    "\n",
    "def get_driver_seq_features(df, driver, year, n_seq=3):\n",
    "    df_hist = df[(df[label_col] == driver) & (df['year'] < year)].sort_values('year', ascending=False)\n",
    "    if len(df_hist) >= n_seq:\n",
    "        feats = df_hist.head(n_seq)[main_features].values\n",
    "    else:\n",
    "        feats = np.vstack([df_hist[main_features].values, np.zeros((n_seq-len(df_hist), len(main_features)))])\n",
    "    return feats\n",
    "\n",
    "X_seq, X_static, y = [], [], []\n",
    "n_seq = 3\n",
    "for i, row in df.iterrows():\n",
    "    X_seq.append(get_driver_seq_features(df, row[label_col], row['year'], n_seq))\n",
    "    # 靜態特徵為 [year, GrandPrix編碼, Team編碼]\n",
    "    X_static.append([row['year'], row['GrandPrix_enc'], row['Team_enc']])\n",
    "    y.append(row['Winner_enc'])\n",
    "X_seq = np.stack(X_seq)\n",
    "X_static = np.array(X_static)\n",
    "y = np.array(y)\n",
    "\n",
    "vc = pd.Series(y).value_counts()\n",
    "valid_labels = vc[vc > 1].index.tolist()\n",
    "mask = [yy in valid_labels for yy in y]\n",
    "X_seq_valid = X_seq[mask]\n",
    "X_static_valid = X_static[mask]\n",
    "y_valid_raw = y[mask]\n",
    "le_valid = LabelEncoder()\n",
    "y_valid = le_valid.fit_transform(y_valid_raw)\n",
    "\n",
    "class LSTMFeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=16, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "    def forward(self, x):\n",
    "        _, (h_n, _) = self.lstm(x)\n",
    "        return h_n[-1]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lstm = LSTMFeatureExtractor(input_size=len(main_features)).to(device)\n",
    "with torch.no_grad():\n",
    "    lstm_features = lstm(torch.tensor(X_seq_valid, dtype=torch.float32).to(device)).cpu().numpy()\n",
    "\n",
    "X_all_valid = np.hstack([lstm_features, X_static_valid])\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_all_valid, y_valid, test_size=0.2, random_state=42, stratify=y_valid\n",
    ")\n",
    "\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=120, learning_rate=0.1, max_depth=4,\n",
    "    objective='multi:softprob', num_class=len(le_valid.classes_)\n",
    ")\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "mean_laps = int(df['Laps'].mean())\n",
    "mean_time = int(df['Time'].mean())\n",
    "mean_position = int(df['Position'].mean()) if df['Position'].mean() > 0 else 1\n",
    "\n",
    "def predict_and_analysis(driver_name, year, grid, grand_prix, team):\n",
    "    # 歷史三場特徵\n",
    "    feats_seq = get_driver_seq_features(df, driver_name, int(year), n_seq)\n",
    "    feats_seq[-1] = [grid, mean_laps, mean_time, mean_position]\n",
    "    X_seq_input = torch.tensor([feats_seq], dtype=torch.float32).to(device)\n",
    "    with torch.no_grad():\n",
    "        lstm_feat = lstm(X_seq_input).cpu().numpy()\n",
    "    # Grand Prix、Team 編碼\n",
    "    gp_enc = le_gp.transform([grand_prix])[0]\n",
    "    team_enc = le_team.transform([team])[0]\n",
    "    X_static_input = np.array([[year, gp_enc, team_enc]])\n",
    "    X_input = np.hstack([lstm_feat, X_static_input])\n",
    "    probs = model.predict_proba(X_input)\n",
    "    top3 = np.argsort(probs[0])[::-1][:3]\n",
    "    orig_names = [le_label.inverse_transform([int(le_valid.classes_[i])])[0] for i in top3]\n",
    "    probs_top = probs[0][top3]\n",
    "    txt = \"\\n\".join([f\"{orig_names[i]}: 機率 {probs_top[i]:.2%}\" for i in range(3)])\n",
    "    return f\"預測TOP3：\\n{txt}\"\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# F1 冠軍預測（LSTM + XGBoost）\")\n",
    "    with gr.Row():\n",
    "        driver = gr.Dropdown(list(le_label.classes_), label=\"車手\")\n",
    "        year = gr.Number(label=\"年份\", value=2024)\n",
    "        grid = gr.Number(label=\"起跑位\", value=1)\n",
    "        grand_prix = gr.Dropdown(list(le_gp.classes_), label=\"Grand Prix\")\n",
    "        team = gr.Dropdown(list(le_team.classes_), label=\"Team\")\n",
    "    btn = gr.Button(\"預測\")\n",
    "    output = gr.Textbox(label=\"預測結果\")\n",
    "    btn.click(\n",
    "        predict_and_analysis,\n",
    "        [driver, year, grid, grand_prix, team],\n",
    "        output\n",
    "    )\n",
    "\n",
    "    def show_analysis():\n",
    "        idx = np.random.choice(len(X_test), 10, replace=False)\n",
    "        Xsub = X_test[idx]\n",
    "        ysub = y_test[idx]\n",
    "        pred_sub = model.predict(Xsub)\n",
    "        orig = [le_label.inverse_transform([int(le_valid.classes_[yy])])[0] for yy in ysub]\n",
    "        pred = [le_label.inverse_transform([int(le_valid.classes_[yy])])[0] for yy in pred_sub]\n",
    "        txt = \"\\n\".join([f\"第{i+1}筆：預測 {p} | 真實 {t}\" for i, (p, t) in enumerate(zip(pred, orig))])\n",
    "        return txt\n",
    "\n",
    "    with gr.Row():\n",
    "        gr.Markdown(\"## 驗證集 10 筆：預測 vs. 真實\")\n",
    "        analysis_btn = gr.Button(\"隨機取10筆驗證\")\n",
    "        analysis_out = gr.Textbox()\n",
    "        analysis_btn.click(show_analysis, [], analysis_out)\n",
    "\n",
    "demo.launch()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
